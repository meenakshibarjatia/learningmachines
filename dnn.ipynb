{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8e95c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X_train = mnist.data[:60000];\n",
    "y_train = mnist.target[:60000];\n",
    "X_test = mnist.data[60000:];\n",
    "y_test = mnist.target[60000:];\n",
    "\n",
    "#normalize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "plt.imshow(X_train[1].reshape(28, 28), cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "print(y_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ip = 28*28\n",
    "n_hid1 = 100\n",
    "n_hid2 = 50\n",
    "n_op = 10\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_ip), name = 'inputs')\n",
    "y = tf.placeholder(tf.int64, shape = (None), name = 'y')\n",
    "is_training = tf.placeholder(tf.bool, shape = (), name = 'is_training')\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "#for batch normalization\n",
    "bn_params = {\n",
    "    'is_training' : is_training,\n",
    "    'decay' : 0.99,\n",
    "    'updates_collections' : None\n",
    "}\n",
    "\n",
    "hidden1 = fully_connected(X, n_hid1, scope = 'hidden1', normalizer_fn = batch_norm, normalizer_params = bn_params, weights_initializer = he_init)\n",
    "hidden2 = fully_connected(hidden1, n_hid2, scope = 'hidden2', normalizer_fn = batch_norm, normalizer_params = bn_params, weights_initializer = he_init)\n",
    "logits = fully_connected(hidden2, n_op, scope = 'outputs', normalizer_fn = batch_norm, normalizer_params = bn_params, weights_initializer = he_init)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = 'loss')\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    cor = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(cor, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 batch: 1199 accuracy train 0.938776 accuracy test 0.9168\n",
      "epoch: 1 batch: 1199 accuracy train 0.959184 accuracy test 0.9366\n",
      "epoch: 2 batch: 1199 accuracy train 0.938776 accuracy test 0.9446\n",
      "epoch: 3 batch: 1199 accuracy train 0.979592 accuracy test 0.9485\n",
      "epoch: 4 batch: 1199 accuracy train 0.959184 accuracy test 0.9521\n",
      "epoch: 5 batch: 1199 accuracy train 0.857143 accuracy test 0.9545\n",
      "epoch: 6 batch: 1199 accuracy train 1.0 accuracy test 0.957\n",
      "epoch: 7 batch: 1199 accuracy train 0.979592 accuracy test 0.959\n",
      "epoch: 8 batch: 1199 accuracy train 0.979592 accuracy test 0.9617\n",
      "epoch: 9 batch: 1199 accuracy train 0.979592 accuracy test 0.962\n",
      "epoch: 10 batch: 1199 accuracy train 0.959184 accuracy test 0.9633\n",
      "epoch: 11 batch: 1199 accuracy train 1.0 accuracy test 0.9637\n",
      "epoch: 12 batch: 1199 accuracy train 1.0 accuracy test 0.9656\n",
      "epoch: 13 batch: 1199 accuracy train 0.979592 accuracy test 0.9657\n",
      "epoch: 14 batch: 1199 accuracy train 0.979592 accuracy test 0.967\n",
      "epoch: 15 batch: 1199 accuracy train 0.959184 accuracy test 0.9673\n",
      "epoch: 16 batch: 1199 accuracy train 0.979592 accuracy test 0.969\n",
      "epoch: 17 batch: 1199 accuracy train 1.0 accuracy test 0.968\n",
      "epoch: 18 batch: 1199 accuracy train 1.0 accuracy test 0.9691\n",
      "epoch: 19 batch: 1199 accuracy train 0.979592 accuracy test 0.9687\n",
      "epoch: 20 batch: 1199 accuracy train 0.959184 accuracy test 0.9687\n",
      "epoch: 21 batch: 1199 accuracy train 1.0 accuracy test 0.97\n",
      "epoch: 22 batch: 1199 accuracy train 1.0 accuracy test 0.9706\n",
      "epoch: 23 batch: 1199 accuracy train 0.979592 accuracy test 0.9711\n",
      "epoch: 24 batch: 1199 accuracy train 0.979592 accuracy test 0.9703\n",
      "epoch: 25 batch: 1199 accuracy train 0.979592 accuracy test 0.972\n",
      "epoch: 26 batch: 1199 accuracy train 0.959184 accuracy test 0.9709\n",
      "epoch: 27 batch: 1199 accuracy train 0.979592 accuracy test 0.9719\n",
      "epoch: 28 batch: 1199 accuracy train 0.979592 accuracy test 0.9724\n",
      "epoch: 29 batch: 1199 accuracy train 0.959184 accuracy test 0.9728\n",
      "epoch: 30 batch: 1199 accuracy train 0.938776 accuracy test 0.9732\n",
      "epoch: 31 batch: 1199 accuracy train 0.979592 accuracy test 0.9732\n",
      "epoch: 32 batch: 1199 accuracy train 0.979592 accuracy test 0.9737\n",
      "epoch: 33 batch: 1199 accuracy train 1.0 accuracy test 0.9735\n",
      "epoch: 34 batch: 1199 accuracy train 0.979592 accuracy test 0.9734\n",
      "epoch: 35 batch: 1199 accuracy train 1.0 accuracy test 0.9744\n",
      "epoch: 36 batch: 1199 accuracy train 0.959184 accuracy test 0.975\n",
      "epoch: 37 batch: 1199 accuracy train 0.918367 accuracy test 0.9743\n",
      "epoch: 38 batch: 1199 accuracy train 1.0 accuracy test 0.9751\n",
      "epoch: 39 batch: 1199 accuracy train 1.0 accuracy test 0.9748\n",
      "epoch: 40 batch: 1199 accuracy train 1.0 accuracy test 0.9754\n",
      "epoch: 41 batch: 1199 accuracy train 1.0 accuracy test 0.9757\n",
      "epoch: 42 batch: 1199 accuracy train 1.0 accuracy test 0.9754\n",
      "epoch: 43 batch: 1199 accuracy train 1.0 accuracy test 0.9759\n",
      "epoch: 44 batch: 1199 accuracy train 1.0 accuracy test 0.9751\n",
      "epoch: 45 batch: 1199 accuracy train 0.979592 accuracy test 0.976\n",
      "epoch: 46 batch: 1199 accuracy train 0.959184 accuracy test 0.9761\n",
      "epoch: 47 batch: 1199 accuracy train 0.959184 accuracy test 0.9763\n",
      "epoch: 48 batch: 1199 accuracy train 1.0 accuracy test 0.9768\n",
      "epoch: 49 batch: 1199 accuracy train 0.959184 accuracy test 0.9767\n",
      "epoch: 50 batch: 1199 accuracy train 1.0 accuracy test 0.9763\n",
      "epoch: 51 batch: 1199 accuracy train 0.979592 accuracy test 0.9769\n",
      "epoch: 52 batch: 1199 accuracy train 0.979592 accuracy test 0.9767\n",
      "epoch: 53 batch: 1199 accuracy train 0.979592 accuracy test 0.9772\n",
      "epoch: 54 batch: 1199 accuracy train 1.0 accuracy test 0.9776\n",
      "epoch: 55 batch: 1199 accuracy train 0.979592 accuracy test 0.9777\n",
      "epoch: 56 batch: 1199 accuracy train 1.0 accuracy test 0.9774\n",
      "epoch: 57 batch: 1199 accuracy train 1.0 accuracy test 0.9776\n",
      "epoch: 58 batch: 1199 accuracy train 1.0 accuracy test 0.9783\n",
      "epoch: 59 batch: 1199 accuracy train 1.0 accuracy test 0.9776\n",
      "epoch: 60 batch: 1199 accuracy train 0.979592 accuracy test 0.9778\n",
      "epoch: 61 batch: 1199 accuracy train 1.0 accuracy test 0.9782\n",
      "epoch: 62 batch: 1199 accuracy train 1.0 accuracy test 0.9782\n",
      "epoch: 63 batch: 1199 accuracy train 0.979592 accuracy test 0.9782\n",
      "epoch: 64 batch: 1199 accuracy train 1.0 accuracy test 0.978\n",
      "epoch: 65 batch: 1199 accuracy train 1.0 accuracy test 0.9792\n",
      "epoch: 66 batch: 1199 accuracy train 1.0 accuracy test 0.9788\n",
      "epoch: 67 batch: 1199 accuracy train 1.0 accuracy test 0.9793\n",
      "epoch: 68 batch: 1199 accuracy train 1.0 accuracy test 0.9786\n",
      "epoch: 69 batch: 1199 accuracy train 0.979592 accuracy test 0.9793\n",
      "epoch: 70 batch: 1199 accuracy train 0.979592 accuracy test 0.9787\n",
      "epoch: 71 batch: 1199 accuracy train 1.0 accuracy test 0.9793\n",
      "epoch: 72 batch: 1199 accuracy train 1.0 accuracy test 0.979\n",
      "epoch: 73 batch: 1199 accuracy train 1.0 accuracy test 0.9792\n",
      "epoch: 74 batch: 1199 accuracy train 1.0 accuracy test 0.9791\n",
      "epoch: 75 batch: 1199 accuracy train 0.938776 accuracy test 0.9794\n",
      "epoch: 76 batch: 1199 accuracy train 1.0 accuracy test 0.9795\n",
      "epoch: 77 batch: 1199 accuracy train 0.979592 accuracy test 0.9796\n",
      "epoch: 78 batch: 1199 accuracy train 1.0 accuracy test 0.9796\n",
      "epoch: 79 batch: 1199 accuracy train 0.959184 accuracy test 0.9796\n",
      "epoch: 80 batch: 1199 accuracy train 1.0 accuracy test 0.9797\n",
      "epoch: 81 batch: 1199 accuracy train 1.0 accuracy test 0.9794\n",
      "epoch: 82 batch: 1199 accuracy train 1.0 accuracy test 0.9805\n",
      "epoch: 83 batch: 1199 accuracy train 1.0 accuracy test 0.9801\n",
      "epoch: 84 batch: 1199 accuracy train 1.0 accuracy test 0.98\n",
      "epoch: 85 batch: 1199 accuracy train 0.979592 accuracy test 0.9802\n",
      "epoch: 86 batch: 1199 accuracy train 1.0 accuracy test 0.9805\n",
      "epoch: 87 batch: 1199 accuracy train 1.0 accuracy test 0.9812\n",
      "epoch: 88 batch: 1199 accuracy train 0.979592 accuracy test 0.9807\n",
      "epoch: 89 batch: 1199 accuracy train 0.959184 accuracy test 0.9804\n",
      "epoch: 90 batch: 1199 accuracy train 0.979592 accuracy test 0.9801\n",
      "epoch: 91 batch: 1199 accuracy train 0.979592 accuracy test 0.9806\n",
      "epoch: 92 batch: 1199 accuracy train 1.0 accuracy test 0.9806\n",
      "epoch: 93 batch: 1199 accuracy train 0.979592 accuracy test 0.9803\n",
      "epoch: 94 batch: 1199 accuracy train 1.0 accuracy test 0.9804\n",
      "epoch: 95 batch: 1199 accuracy train 0.979592 accuracy test 0.9801\n",
      "epoch: 96 batch: 1199 accuracy train 0.979592 accuracy test 0.9798\n",
      "epoch: 97 batch: 1199 accuracy train 1.0 accuracy test 0.9809\n",
      "epoch: 98 batch: 1199 accuracy train 1.0 accuracy test 0.9801\n",
      "epoch: 99 batch: 1199 accuracy train 1.0 accuracy test 0.981\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "m = X_train.shape[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        Xtrainsh, ytrainsh = shuffle(X_train, y_train)\n",
    "        for batch in range(int(np.floor(m/batch_size))):\n",
    "            Xcur = Xtrainsh[batch_size*batch : batch_size*batch + batch_size - 1]\n",
    "            ycur = ytrainsh[batch_size*batch : batch_size*batch + batch_size - 1]\n",
    "            sess.run(training_op, feed_dict = {is_training : True, X : Xcur, y :ycur})\n",
    "        acc_train = accuracy.eval(feed_dict = {is_training : False, X: Xcur, y:ycur})\n",
    "        acc_test = accuracy.eval(feed_dict = {is_training : False, X: X_test, y:y_test})\n",
    "        print('epoch:', epoch, 'batch:', batch, 'accuracy train', acc_train, 'accuracy test', acc_test)\n",
    "    save_path = saver.save(sess, './dnn_chkpt.ckpt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
